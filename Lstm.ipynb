{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lstm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMy40oo/e23ulg2GQKgLOQR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vaincookie/FundamentalAnalysis/blob/master/Lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1108rPFuk4D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d1f8323-2fca-4b0a-9b76-221224069cb6"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Oct 24 19:15:04 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.74       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P0    35W / 250W |   6743MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNBglDhXhWWN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2b58be5-1d36-4d50-9ea9-f23488fabf08"
      },
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 13.6 gigabytes of available RAM\n",
            "\n",
            "Not using a high-RAM runtime\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5ewiidP3U2h"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import trange\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data \n",
        "\n",
        "train= pd.read_csv('../content/train.csv')\n",
        "test= pd.read_csv('../content/test.csv')\n",
        "test_ids= test['id'].to_numpy()"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "au9wlmnp3z-L"
      },
      "source": [
        "start = time.time()"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sz2jUJRr33D2"
      },
      "source": [
        "def preprocess(df):\n",
        "    dfr= pd.get_dummies(df['R'], prefix= \"R_\")\n",
        "    df= pd.concat([df, dfr], axis= 1)\n",
        "    dfc= pd.get_dummies(df['C'], prefix= \"C_\")\n",
        "    df= pd.concat([df, dfc], axis= 1)\n",
        "    df= df.drop(['R', 'C'], axis= 1)\n",
        "\n",
        "    df['u_in_cumsum']= df['u_in'].groupby(df['breath_id']).cumsum()\n",
        "    df['time_step_cumsum']= df['time_step'].groupby(df['breath_id']).cumsum()\n",
        "    \n",
        "    df['u_in_min']= df['u_in'].groupby(df['breath_id']).transform('min')\n",
        "    df['u_in_max']= df['u_in'].groupby(df['breath_id']).transform('max')\n",
        "    df['u_in_mean']= df['u_in'].groupby(df['breath_id']).transform('mean')\n",
        "   \n",
        "    df['u_in_lag2']= df['u_in'].groupby(df['breath_id']).shift(2)\n",
        "    df['u_in_lag1']= df['u_in'].groupby(df['breath_id']).shift(1)\n",
        "    df['u_in_lag-1']= df['u_in'].groupby(df['breath_id']).shift(-1)\n",
        "    df['u_in_lag-2']= df['u_in'].groupby(df['breath_id']).shift(-2)\n",
        "    df= df.fillna(0)\n",
        "\n",
        "    df['u_in_diff1']= df['u_in']- df['u_in_lag1']\n",
        "    df['u_in_diff2']= df['u_in']- df['u_in_lag2']\n",
        "    df['u_in_diff3']= df['u_in_max']- df['u_in']\n",
        "    df['u_in_diff4']= df['u_in_mean']- df['u_in']\n",
        "\n",
        "    df1= df[df['u_out'] == 0]\n",
        "    df['mean_inspiratory_uin']= df1['u_in'].groupby(df['breath_id']).transform('mean')\n",
        "\n",
        "    df2= df[df['u_out'] == 1]\n",
        "    df['mean_expiratory_uin']= df2['u_in'].groupby(df['breath_id']).transform('mean')\n",
        "    \n",
        "    df['u_in_diff5']= df['mean_inspiratory_uin']- df['u_in']\n",
        "    df['u_in_diff6']= df['mean_expiratory_uin']- df['u_in']\n",
        "    \n",
        "    df= df.fillna(0)\n",
        "    \n",
        "    df['delta_t']= df.groupby('breath_id')['time_step'].diff().fillna(0)\n",
        "    df['delta_uin']= df.groupby('breath_id')['u_in'].diff().fillna(0)\n",
        "    \n",
        "    df['area']= df['u_in']*df['delta_t']\n",
        "    df['area']= df.groupby('breath_id')['area'].cumsum()\n",
        "    df['slope']= (df['delta_uin']/df['delta_t']).fillna(0)\n",
        "\n",
        "    return df"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YJTfs1m7LP-"
      },
      "source": [
        ""
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIeL6wK_4eLE"
      },
      "source": [
        "groups= train.breath_id.values.reshape(-1, 80)[:, 0]\n",
        "groups.shape\n",
        "\n",
        "train= preprocess(train)\n",
        "targets= train['pressure'].to_numpy().reshape(-1, 80)\n",
        "train.drop(['id','pressure', \"breath_id\"], axis= 1, inplace= True)\n",
        "\n",
        "test= preprocess(test)\n",
        "test.drop(['id', \"breath_id\"], axis= 1, inplace= True)\n",
        "y_test= np.zeros(test.shape[0]).reshape(-1, 80)\n",
        "\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "RS = RobustScaler()\n",
        "train = RS.fit_transform(train)\n",
        "test  = RS.transform(test)\n",
        "\n",
        "num_features= train.shape[-1]\n",
        "train= train.reshape(-1, 80, num_features)\n",
        "test= test.reshape(-1, 80, num_features)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLWbbMo67MD7"
      },
      "source": [
        "class CustomDataset:\n",
        "    def __init__(self, data, target):\n",
        "        self.data= data\n",
        "        self.target= target\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        current_sample= self.data[idx, :, :]\n",
        "        current_target= self.target[idx, :]\n",
        "        \n",
        "        return torch.tensor(current_sample, dtype= torch.float), torch.tensor(current_target, dtype= torch.float)\n",
        "     "
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5jay2x97NKv"
      },
      "source": [
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(RNNModel, self).__init__()\n",
        "        \n",
        "        hidden_dim= [400, 300, 200, 100]\n",
        "        self.bilstm1= nn.LSTM(input_dim, hidden_dim[0], batch_first= True, bidirectional= True)\n",
        "        self.norm1= nn.LayerNorm(hidden_dim[0]*2)\n",
        "        \n",
        "        self.bilstm2= nn.LSTM(hidden_dim[0]*2, hidden_dim[1], batch_first= True, bidirectional= True)\n",
        "        self.norm2= nn.LayerNorm(hidden_dim[1]*2)\n",
        "        \n",
        "        self.bilstm3= nn.LSTM(hidden_dim[1]*2, hidden_dim[2], batch_first= True, bidirectional= True)\n",
        "        self.norm3= nn.LayerNorm(hidden_dim[2]*2)\n",
        "        \n",
        "        self.bilstm4= nn.LSTM(hidden_dim[2]*2, hidden_dim[3], batch_first= True, bidirectional= True)\n",
        "        self.norm4= nn.LayerNorm(hidden_dim[3]*2)\n",
        "        \n",
        "        self.d= nn.Dropout(p= 0.002)\n",
        "        \n",
        "        self.fc1= nn.Linear(hidden_dim[3]*2, 100)\n",
        "        self.fc2= nn.Linear(100, output_dim)\n",
        "#         self.fc3= nn.Linear(32, output_dim)\n",
        "\n",
        "        \n",
        "    def forward(self, X):\n",
        "        pred, _= self.bilstm1(X)\n",
        "        pred= self.norm1(pred)\n",
        "        \n",
        "        pred, _= self.bilstm2(pred)\n",
        "        pred= self.norm2(pred)\n",
        "        \n",
        "        pred, _= self.bilstm3(pred)\n",
        "        pred= self.norm3(pred)\n",
        "        \n",
        "        pred, _= self.bilstm4(pred)\n",
        "        pred= self.norm4(pred)\n",
        "        \n",
        "        pred= self.d(pred)\n",
        "        \n",
        "        pred= self.fc1(pred)\n",
        "        pred= F.selu(pred)\n",
        "        \n",
        "        pred= self.fc2(pred)\n",
        "        \n",
        "#         pred= F.selu(pred)\n",
        "#         pred= self.fc3(pred)\n",
        "\n",
        "        pred= pred.squeeze(dim= 2)\n",
        "        \n",
        "        return pred"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0Fa4are-w5M"
      },
      "source": [
        "def initialize_parameters(m):\n",
        "    if isinstance(m, nn.LSTM):\n",
        "        nn.init.orthogonal_(m.weight_ih_l0.data, gain= nn.init.calculate_gain('tanh'))\n",
        "        nn.init.orthogonal_(m.weight_hh_l0.data, gain= nn.init.calculate_gain('tanh'))\n",
        "        nn.init.orthogonal_(m.weight_ih_l0_reverse.data, gain= nn.init.calculate_gain('tanh'))\n",
        "        nn.init.orthogonal_(m.weight_hh_l0_reverse.data, gain= nn.init.calculate_gain('tanh'))\n",
        "        \n",
        "        nn.init.constant_(m.bias_ih_l0.data, 0)\n",
        "        nn.init.constant_(m.bias_hh_l0.data, 0)\n",
        "        nn.init.constant_(m.bias_ih_l0_reverse.data, 0)\n",
        "        nn.init.constant_(m.bias_hh_l0_reverse.data, 0)\n",
        "        \n",
        "    if isinstance(m, nn.Linear):\n",
        "        nn.init.xavier_normal_(m.weight.data)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfvNeqGKtAEj"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMlt9DMr-zQi"
      },
      "source": [
        "device= \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
        "INPUT_DIM= num_features\n",
        "OUTPUT_DIM= 1\n",
        "BATCH_SIZE= 1024\n",
        "\n",
        "model= RNNModel(input_dim= INPUT_DIM, output_dim= OUTPUT_DIM).to(device)\n",
        "model.apply(initialize_parameters)\n",
        "\n",
        "criterion= nn.L1Loss()\n",
        "criterion.to(device)\n",
        "\n",
        "optimizer= optim.Adam(model.parameters(), lr= 0.0001)\n",
        "scheduler= optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor= 0.5, patience= 10, verbose= True)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cskk1zehryej"
      },
      "source": [
        "def train_model(dataloader, model, criterion, optimizer):\n",
        "    size= len(dataloader.dataset)\n",
        "    model.train()\n",
        "    batches= len(dataloader)\n",
        "    train_loss= 0\n",
        "    \n",
        "    for batch_idx, (X, y) in enumerate(dataloader):\n",
        "        X, y= X.to(device), y.to(device)\n",
        "\n",
        "        scores= model(X)\n",
        "        loss= criterion(scores, y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        loss= loss.item()\n",
        "        train_loss += loss\n",
        "        \n",
        "    train_loss_avg= train_loss/batches\n",
        "    print(f\"avg. train loss: {train_loss_avg}\")\n",
        "    \n",
        "    return train_loss_avg"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNxz75uMrzLa"
      },
      "source": [
        "def val_model(dataloader, model, criterion):\n",
        "    \n",
        "    size= len(dataloader.dataset)\n",
        "    batches= len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss= 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in (dataloader):\n",
        "            X, y= X.to(device), y.to(device)\n",
        "      \n",
        "            scores= model(X)\n",
        "            test_loss += criterion(scores, y)\n",
        "\n",
        "    test_loss /= batches\n",
        "\n",
        "    print(f\"avg test loss : {test_loss}\")\n",
        "    \n",
        "    return test_loss"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4S9wWs4Vr0dh"
      },
      "source": [
        "def val_model(dataloader, model, criterion):\n",
        "    \n",
        "    size= len(dataloader.dataset)\n",
        "    batches= len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss= 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in (dataloader):\n",
        "            X, y= X.to(device), y.to(device)\n",
        "      \n",
        "            scores= model(X)\n",
        "            test_loss += criterion(scores, y)\n",
        "\n",
        "    test_loss /= batches\n",
        "\n",
        "    print(f\"avg test loss : {test_loss}\")\n",
        "    \n",
        "    return test_loss"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 631
        },
        "id": "luLi-rsIr1xh",
        "outputId": "f289ed5f-7680-4fcf-cac6-8686091f5fc4"
      },
      "source": [
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "kfold= GroupKFold(n_splits= 5)\n",
        "EPOCHS= 300\n",
        "cv_scores= []\n",
        "predictions= np.zeros(test_ids.shape[0])\n",
        "\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kfold.split(train, targets, groups= groups)):\n",
        "    X_train, X_val= train[train_idx], train[val_idx]\n",
        "    y_train, y_val= targets[train_idx], targets[val_idx]\n",
        "    \n",
        "    train_dataset= CustomDataset(data= X_train, target= y_train)\n",
        "    val_dataset= CustomDataset(data= X_val, target= y_val)\n",
        "\n",
        "    train_loader= data.DataLoader(train_dataset, batch_size= BATCH_SIZE)\n",
        "    val_loader= data.DataLoader(val_dataset, batch_size= BATCH_SIZE)\n",
        "    \n",
        "    best_valid_loss= float('inf')\n",
        "    \n",
        "    avg_train_losses= []\n",
        "    avg_val_losses= []\n",
        "    \n",
        "    for t in trange(EPOCHS):\n",
        "        print(f\"Epoch: {t+1}\")\n",
        "        train_loss= train_model(train_loader, model, criterion, optimizer)\n",
        "        val_loss= val_model(val_loader, model, criterion)\n",
        "        \n",
        "        avg_train_losses.append(train_loss)\n",
        "        avg_val_losses.append(val_loss)\n",
        "        \n",
        "        if (val_loss< best_valid_loss):\n",
        "            best_valid_loss= val_loss\n",
        "            ofilename = 'ventilator%d.pth' % fold\n",
        "            torch.save(model.state_dict(),  ofilename)\n",
        "        \n",
        "        scheduler.step(val_loss)\n",
        "    \n",
        "    cv_scores.append(best_valid_loss)\n",
        "    \n",
        "    test_dataset= CustomDataset(data= test, target= y_test)\n",
        "    test_loader= data.DataLoader(test_dataset, batch_size= BATCH_SIZE)\n",
        "                       \n",
        "    model.load_state_dict(torch.load('ventilator%d.pth' % fold, map_location=device))\n",
        "    predictions += (predict_model(test_loader, model))\n",
        "    \n",
        "    break"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/500 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1\n",
            "avg. train loss: 3.165274048255662\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 1/500 [00:33<4:40:03, 33.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avg test loss : 1.703231692314148\n",
            "Epoch: 2\n",
            "avg. train loss: 1.2630122627242137\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 2/500 [01:07<4:39:35, 33.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avg test loss : 0.9504106640815735\n",
            "Epoch: 3\n",
            "avg. train loss: 0.8268881945286767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 3/500 [01:41<4:39:26, 33.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avg test loss : 0.7296004295349121\n",
            "Epoch: 4\n",
            "avg. train loss: 0.6820706179586508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 4/500 [02:14<4:38:52, 33.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avg test loss : 0.6401387453079224\n",
            "Epoch: 5\n",
            "avg. train loss: 0.6055709871195131\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 5/500 [02:48<4:38:36, 33.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avg test loss : 0.5767314434051514\n",
            "Epoch: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 5/500 [03:13<5:19:33, 38.73s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-fffbdf9715f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch: {t+1}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mval_loss\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-bf0adb848e0b>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(dataloader, model, criterion, optimizer)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBBbOf53r36a"
      },
      "source": [
        "sub= pd.DataFrame({'id': test_ids, 'pressure': predictions})\n",
        "sub.to_csv('submission.csv',index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8-NsQ-lr-_H"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(avg_train_losses)\n",
        "plt.plot(avg_val_losses)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}